{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.01598827526480581,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00026647125441343016,
      "grad_norm": 0.3156489133834839,
      "learning_rate": 4e-05,
      "loss": 2.233,
      "step": 1
    },
    {
      "epoch": 0.0005329425088268603,
      "grad_norm": 0.3889226019382477,
      "learning_rate": 8e-05,
      "loss": 2.0947,
      "step": 2
    },
    {
      "epoch": 0.0007994137632402904,
      "grad_norm": 0.20904771983623505,
      "learning_rate": 0.00012,
      "loss": 2.3037,
      "step": 3
    },
    {
      "epoch": 0.0010658850176537206,
      "grad_norm": 0.25202035903930664,
      "learning_rate": 0.00016,
      "loss": 2.0188,
      "step": 4
    },
    {
      "epoch": 0.0013323562720671507,
      "grad_norm": 0.5459492206573486,
      "learning_rate": 0.0002,
      "loss": 2.1968,
      "step": 5
    },
    {
      "epoch": 0.0015988275264805809,
      "grad_norm": 0.28155115246772766,
      "learning_rate": 0.00019636363636363636,
      "loss": 1.8105,
      "step": 6
    },
    {
      "epoch": 0.001865298780894011,
      "grad_norm": 0.31298017501831055,
      "learning_rate": 0.00019272727272727274,
      "loss": 2.0492,
      "step": 7
    },
    {
      "epoch": 0.0021317700353074413,
      "grad_norm": 0.3997596502304077,
      "learning_rate": 0.0001890909090909091,
      "loss": 1.8862,
      "step": 8
    },
    {
      "epoch": 0.002398241289720871,
      "grad_norm": 0.38479870557785034,
      "learning_rate": 0.00018545454545454545,
      "loss": 1.5954,
      "step": 9
    },
    {
      "epoch": 0.0026647125441343015,
      "grad_norm": 0.5823689699172974,
      "learning_rate": 0.00018181818181818183,
      "loss": 2.0349,
      "step": 10
    },
    {
      "epoch": 0.002931183798547732,
      "grad_norm": 0.31213584542274475,
      "learning_rate": 0.0001781818181818182,
      "loss": 1.7297,
      "step": 11
    },
    {
      "epoch": 0.0031976550529611617,
      "grad_norm": 0.37236177921295166,
      "learning_rate": 0.00017454545454545454,
      "loss": 2.0313,
      "step": 12
    },
    {
      "epoch": 0.003464126307374592,
      "grad_norm": 0.3896167278289795,
      "learning_rate": 0.0001709090909090909,
      "loss": 1.6198,
      "step": 13
    },
    {
      "epoch": 0.003730597561788022,
      "grad_norm": 0.361473947763443,
      "learning_rate": 0.00016727272727272728,
      "loss": 1.9228,
      "step": 14
    },
    {
      "epoch": 0.003997068816201452,
      "grad_norm": 0.32876425981521606,
      "learning_rate": 0.00016363636363636366,
      "loss": 1.7367,
      "step": 15
    },
    {
      "epoch": 0.0042635400706148826,
      "grad_norm": 0.4062846899032593,
      "learning_rate": 0.00016,
      "loss": 1.5565,
      "step": 16
    },
    {
      "epoch": 0.004530011325028313,
      "grad_norm": 0.32174649834632874,
      "learning_rate": 0.00015636363636363637,
      "loss": 1.4166,
      "step": 17
    },
    {
      "epoch": 0.004796482579441742,
      "grad_norm": 0.282687783241272,
      "learning_rate": 0.00015272727272727275,
      "loss": 1.9512,
      "step": 18
    },
    {
      "epoch": 0.005062953833855173,
      "grad_norm": 0.5609829425811768,
      "learning_rate": 0.0001490909090909091,
      "loss": 1.957,
      "step": 19
    },
    {
      "epoch": 0.005329425088268603,
      "grad_norm": 0.3307248651981354,
      "learning_rate": 0.00014545454545454546,
      "loss": 1.6312,
      "step": 20
    },
    {
      "epoch": 0.005595896342682033,
      "grad_norm": 0.25755977630615234,
      "learning_rate": 0.00014181818181818184,
      "loss": 1.9339,
      "step": 21
    },
    {
      "epoch": 0.005862367597095464,
      "grad_norm": 0.30693766474723816,
      "learning_rate": 0.0001381818181818182,
      "loss": 1.786,
      "step": 22
    },
    {
      "epoch": 0.006128838851508893,
      "grad_norm": 0.38162755966186523,
      "learning_rate": 0.00013454545454545455,
      "loss": 1.8984,
      "step": 23
    },
    {
      "epoch": 0.006395310105922323,
      "grad_norm": 0.2853011190891266,
      "learning_rate": 0.00013090909090909093,
      "loss": 2.0886,
      "step": 24
    },
    {
      "epoch": 0.006661781360335754,
      "grad_norm": 0.4976370632648468,
      "learning_rate": 0.00012727272727272728,
      "loss": 1.9127,
      "step": 25
    },
    {
      "epoch": 0.006928252614749184,
      "grad_norm": 0.35627779364585876,
      "learning_rate": 0.00012363636363636364,
      "loss": 1.5696,
      "step": 26
    },
    {
      "epoch": 0.007194723869162614,
      "grad_norm": 0.5457394123077393,
      "learning_rate": 0.00012,
      "loss": 1.5654,
      "step": 27
    },
    {
      "epoch": 0.007461195123576044,
      "grad_norm": 0.35445526242256165,
      "learning_rate": 0.00011636363636363636,
      "loss": 1.6281,
      "step": 28
    },
    {
      "epoch": 0.007727666377989474,
      "grad_norm": 1.1197772026062012,
      "learning_rate": 0.00011272727272727272,
      "loss": 1.8561,
      "step": 29
    },
    {
      "epoch": 0.007994137632402904,
      "grad_norm": 0.47607386112213135,
      "learning_rate": 0.00010909090909090909,
      "loss": 1.5683,
      "step": 30
    },
    {
      "epoch": 0.008260608886816335,
      "grad_norm": 0.507258951663971,
      "learning_rate": 0.00010545454545454545,
      "loss": 1.8524,
      "step": 31
    },
    {
      "epoch": 0.008527080141229765,
      "grad_norm": 0.3631422221660614,
      "learning_rate": 0.00010181818181818181,
      "loss": 2.0329,
      "step": 32
    },
    {
      "epoch": 0.008793551395643195,
      "grad_norm": 0.3863156735897064,
      "learning_rate": 9.818181818181818e-05,
      "loss": 1.8118,
      "step": 33
    },
    {
      "epoch": 0.009060022650056626,
      "grad_norm": 0.3391605317592621,
      "learning_rate": 9.454545454545455e-05,
      "loss": 1.7521,
      "step": 34
    },
    {
      "epoch": 0.009326493904470056,
      "grad_norm": 0.36820709705352783,
      "learning_rate": 9.090909090909092e-05,
      "loss": 1.7902,
      "step": 35
    },
    {
      "epoch": 0.009592965158883485,
      "grad_norm": 0.24950620532035828,
      "learning_rate": 8.727272727272727e-05,
      "loss": 1.7557,
      "step": 36
    },
    {
      "epoch": 0.009859436413296915,
      "grad_norm": 0.27664220333099365,
      "learning_rate": 8.363636363636364e-05,
      "loss": 1.4091,
      "step": 37
    },
    {
      "epoch": 0.010125907667710345,
      "grad_norm": 0.4821006953716278,
      "learning_rate": 8e-05,
      "loss": 1.8437,
      "step": 38
    },
    {
      "epoch": 0.010392378922123776,
      "grad_norm": 0.30486226081848145,
      "learning_rate": 7.636363636363637e-05,
      "loss": 2.0829,
      "step": 39
    },
    {
      "epoch": 0.010658850176537206,
      "grad_norm": 0.37898486852645874,
      "learning_rate": 7.272727272727273e-05,
      "loss": 1.4806,
      "step": 40
    },
    {
      "epoch": 0.010925321430950636,
      "grad_norm": 0.3682231605052948,
      "learning_rate": 6.90909090909091e-05,
      "loss": 1.764,
      "step": 41
    },
    {
      "epoch": 0.011191792685364067,
      "grad_norm": 0.3923039734363556,
      "learning_rate": 6.545454545454546e-05,
      "loss": 1.779,
      "step": 42
    },
    {
      "epoch": 0.011458263939777497,
      "grad_norm": 0.4940616190433502,
      "learning_rate": 6.181818181818182e-05,
      "loss": 1.8239,
      "step": 43
    },
    {
      "epoch": 0.011724735194190927,
      "grad_norm": 0.3191487789154053,
      "learning_rate": 5.818181818181818e-05,
      "loss": 1.7756,
      "step": 44
    },
    {
      "epoch": 0.011991206448604358,
      "grad_norm": 0.37162914872169495,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 1.7595,
      "step": 45
    },
    {
      "epoch": 0.012257677703017786,
      "grad_norm": 0.3212052285671234,
      "learning_rate": 5.090909090909091e-05,
      "loss": 1.6821,
      "step": 46
    },
    {
      "epoch": 0.012524148957431216,
      "grad_norm": 0.4086299240589142,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 1.6394,
      "step": 47
    },
    {
      "epoch": 0.012790620211844647,
      "grad_norm": 0.3029012978076935,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 1.8008,
      "step": 48
    },
    {
      "epoch": 0.013057091466258077,
      "grad_norm": 0.30512669682502747,
      "learning_rate": 4e-05,
      "loss": 1.9566,
      "step": 49
    },
    {
      "epoch": 0.013323562720671507,
      "grad_norm": 0.4587368667125702,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 2.0162,
      "step": 50
    },
    {
      "epoch": 0.013590033975084938,
      "grad_norm": 0.34138208627700806,
      "learning_rate": 3.272727272727273e-05,
      "loss": 1.7189,
      "step": 51
    },
    {
      "epoch": 0.013856505229498368,
      "grad_norm": 0.30367565155029297,
      "learning_rate": 2.909090909090909e-05,
      "loss": 1.5503,
      "step": 52
    },
    {
      "epoch": 0.014122976483911798,
      "grad_norm": 0.3483194410800934,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 1.7739,
      "step": 53
    },
    {
      "epoch": 0.014389447738325229,
      "grad_norm": 0.30712008476257324,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 1.5778,
      "step": 54
    },
    {
      "epoch": 0.014655918992738659,
      "grad_norm": 0.32513585686683655,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 1.6882,
      "step": 55
    },
    {
      "epoch": 0.014922390247152088,
      "grad_norm": 0.35062918066978455,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 1.5707,
      "step": 56
    },
    {
      "epoch": 0.015188861501565518,
      "grad_norm": 0.5524559020996094,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 1.9333,
      "step": 57
    },
    {
      "epoch": 0.015455332755978948,
      "grad_norm": 0.4573323130607605,
      "learning_rate": 7.272727272727272e-06,
      "loss": 1.7401,
      "step": 58
    },
    {
      "epoch": 0.01572180401039238,
      "grad_norm": 0.24614807963371277,
      "learning_rate": 3.636363636363636e-06,
      "loss": 1.9466,
      "step": 59
    },
    {
      "epoch": 0.01598827526480581,
      "grad_norm": 0.41136404871940613,
      "learning_rate": 0.0,
      "loss": 1.7834,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2328791271094272.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
